# Frontend Web Application

**Next.js React frontend for the AI Chat System with RAG and Performance Analytics.**

## ğŸš€ Quick Start

```bash
# Install dependencies
npm install

# Setup environment
cp .env.local.example .env.local
# Edit .env.local with backend API URL

# Start development server
npm run dev
```

**App will be available at:** http://localhost:3000

## ğŸ“‹ Key Features

- **ğŸ’¬ Real-time Chat**: Persistent chat sessions with AI
- **ğŸ“š RAG Integration**: Upload documents for contextual responses
- **ğŸ›ï¸ AI Configuration**: Switch between OpenAI and Ollama models
- **ğŸ“Š Analytics Dashboard**: Performance metrics and AI insights
- **ğŸ¨ Modern UI**: Tailwind CSS + Shadcn/ui components
- **ğŸ“± Responsive Design**: Mobile-friendly interface

## ğŸ›  Available Scripts

```bash
npm run dev          # Development server
npm run build        # Production build
npm run start        # Production server
npm run lint         # ESLint checking
```

## ğŸ— Project Structure

```
app/                 # Next.js App Router pages
â”œâ”€â”€ chat/           # Chat interface page
â”œâ”€â”€ analytics/      # Performance analytics page
â”œâ”€â”€ config/         # AI configuration page
â””â”€â”€ layout.tsx      # Root layout

components/          # Reusable UI components
â”œâ”€â”€ ui/             # Base components (buttons, inputs, etc.)
â””â”€â”€ root-layout-client.tsx

features/           # Feature-specific components
â”œâ”€â”€ chat/           # Chat functionality
â”œâ”€â”€ ai-config/      # AI configuration forms
â””â”€â”€ analytics/      # Analytics charts

lib/                # Utilities and configurations
â”œâ”€â”€ api/            # API client and hooks
â”œâ”€â”€ services/       # Business logic
â””â”€â”€ utils.ts        # Helper functions
```

## âš™ï¸ Configuration

### Environment Variables (.env.local)
```bash
# Backend API Base (no trailing /api â€” the app will append /api automatically)
NEXT_PUBLIC_API_BASE=http://localhost:3001

# For production deployment
NEXT_PUBLIC_API_BASE=https://your-backend.example.com
```

## ğŸ“¡ Key Components

### Chat Interface
- **Real-time messaging** with AI providers
- **Session persistence** across page reloads
- **RAG mode toggle** for document-enhanced responses
- **Message history** with timestamps

### AI Configuration
- **Provider selection** (OpenAI/Ollama)
- **Model selection** per provider
- **Parameter tuning** (temperature, max tokens)
- **Configuration persistence**

### Analytics Dashboard
- **Performance metrics** visualization
- **AI-powered insights** and recommendations
- **Health scoring** with trend analysis
- **Interactive charts** using Recharts

### Document Upload (RAG)
- **Drag & drop interface** for file uploads
- **Progress indicators** during processing
- **Knowledge base management**
- **Document preview** and organization

## ğŸ¨ UI Components

Built with modern, accessible components:
- **Tailwind CSS** for styling
- **Shadcn/ui** component library
- **Lucide React** for icons
- **Recharts** for data visualization
- **React Hook Form** for forms

## ğŸ“± Responsive Design

- **Mobile-first** approach
- **Tablet optimization**
- **Desktop layouts**
- **Touch-friendly** interactions

## ğŸ”— API Integration

Uses **TanStack Query** for:
- **Caching** API responses
- **Background updates**
- **Optimistic updates**
- **Error handling**
- **Loading states**

## ğŸŒ Deployment

### Vercel (Recommended)
1. Connect GitHub repository to Vercel
2. Set environment variable: `NEXT_PUBLIC_API_BASE` (e.g., https://your-backend.example.com)
3. Optionally, set `public/config.json` at deploy time to point to your backend; the env var overrides it when present
4. Deploy automatically on git push

### Manual Deployment
```bash
# Build for production
npm run build

# Start production server
npm run start
```

### Docker
```bash
# Build and run with Docker
docker build -t ai-frontend .
docker run -p 3000:3000 ai-frontend
```

For complete setup instructions, see the main project README.
